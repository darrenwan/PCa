#Modify this file according to your project setting.
#To konw how it works, refer to this page:
#https://docs.python.org/3/library/configparser.html 

[DEFAULT]
FloatPrecision = 4
Random_seed = 
n_jobs = 1
Dir = C:\D\Hitales\胰腺模型\原始数据\Pipeline\
#y列
Label_name = 分组 


[TRAIN]
#原始数据
Data_dir = ${DEFAULT:Dir}raw\
Label_file = ${Data_dir}20180929入组完成.txt
Label_name = 分组
Label_file_header = ['PID', '年龄', '性别', '分组']
Label_encode = {'PDAC': 0, '健康查体': 1, '慢性胰腺炎': 2}
Max_str_ratio = 0.3
Examine_name = ${Data_dir}化验标准名转化.txt
Specified_feature = ['CA125', '淀粉酶', '纤维蛋白原（FIB）', '凝血酶时间（TT）',
    '凝血酶原时间（PT）', '活化部分凝血活酶时间（APTT）']


[TASK_ATTR]
Output_dir = ${DEFAULT:Dir}output\
Train_file = ${Output_dir}train.xlsx
Test_file = ${Output_dir}test.xlsx
Feature_file = ${Output_dir}特征类型统计.xlsx
Num_class = 4
Log_file = ${Output_dir}Logger
Model_file = ${Output_dir}Model

[DEPLOY]
MySQL = {
    'host': 'localhost',
    'user': 'root',
    'password': 'hitales',
    'db': 'medical',
    'charset': 'utf8mb4',
    'cursorclass': pymysql.cursors.DictCursor
    }


[MODEL_PARAMS]
LogisticRegression__params = {
    'penalty': ['l1', 'l2'],
    'C': [0.1, 0.5, 1, 2, 4]
    }
SVC__params = {
    'C': [1, 2, 4],
    }
MLPClassifier__params = {
    'hidden_layer_sizes': [(50, 50), (100, 100), (200, 200), (300, 300)]
    }
GaussianNB__params = {
    }
KNeighborsClassifier__params = {
    'n_neighbors': [3, 5, 7, 10, 15],
    'leaf_size': [5, 10, 20, 30, 40],
    'p': [1, 2]
    }  
AdaBoostClassifier__params = {
    'n_estimators': [100, 200, 400],
    'learning_rate': [0.1, 0.5, 1],
    }    
RandomForestClassifier__params = {
    'n_estimators': [100, 200, 400],
    'max_depth': [None, 3, 4],    
    'max_features': ['auto', None]
    }   
GradientBoostingClassifier__params = {
    'learning_rate': [0.02, 0.1, 0.5],
    'n_estimators': [100, 200, 400],
    'max_depth': [2, 3, 4]
    }
XGBClassifier__params = {
    'n_estimators': [100, 200, 400],
    'learning_rate': [0.02, 0.1, 0.5],
    'max_depth': [3, 4, 5],
    } 
LGBMClassifier__params = {
    'n_estimators': [100, 200, 400],
    'num_leaves': [15, 31, 47],    
    'learning_rate': [0.02, 0.1, 0.5]
    }


